#!/usr/bin/env python3
"""
Advanced CSI2-V4L2 Integration Test
===================================
ì´ ìŠ¤í¬ë¦½íŠ¸ëŠ” QEMUì—ì„œ CSI2ì™€ V4L2 í†µí•©ì„ í¬ê´„ì ìœ¼ë¡œ í…ŒìŠ¤íŠ¸í•©ë‹ˆë‹¤.
"""

import cv2
import numpy as np
import time
import sys
import os
import fcntl
import struct
import mmap
from pathlib import Path
import json
import threading
import queue

# V4L2 ìƒìˆ˜ë“¤
V4L2_CAP_VIDEO_CAPTURE = 0x00000001
V4L2_CAP_STREAMING = 0x04000000
VIDIOC_QUERYCAP = 0x80685600
VIDIOC_G_FMT = 0xc0cc5604
VIDIOC_S_FMT = 0xc0cc5605

class CSI2V4L2Tester:
    def __init__(self, device_path="/dev/video0"):
        self.device_path = device_path
        self.cap = None
        self.test_results = {}
        self.frame_queue = queue.Queue(maxsize=100)
        self.stop_capture = False
        
    def log(self, message, level="INFO"):
        """ë¡œê·¸ ë©”ì‹œì§€ ì¶œë ¥"""
        timestamp = time.strftime("%H:%M:%S")
        icons = {"INFO": "â„¹ï¸", "SUCCESS": "âœ…", "WARNING": "âš ï¸", "ERROR": "âŒ"}
        print(f"[{timestamp}] {icons.get(level, 'ğŸ“')} {message}")
        
    def test_device_discovery(self):
        """ë””ë°”ì´ìŠ¤ ë°œê²¬ í…ŒìŠ¤íŠ¸"""
        self.log("Testing device discovery...")
        
        # /dev/video* ë””ë°”ì´ìŠ¤ë“¤ ê²€ìƒ‰
        video_devices = list(Path("/dev").glob("video*"))
        self.log(f"Found {len(video_devices)} video devices: {[str(d) for d in video_devices]}")
        
        # ë©”ì¸ ë””ë°”ì´ìŠ¤ ì¡´ì¬ í™•ì¸
        if Path(self.device_path).exists():
            self.log(f"Target device {self.device_path} exists", "SUCCESS")
            return True
        else:
            self.log(f"Target device {self.device_path} not found", "ERROR")
            return False
    
    def test_v4l2_capabilities(self):
        """V4L2 capabilities ì§ì ‘ í…ŒìŠ¤íŠ¸"""
        self.log("Testing V4L2 capabilities directly...")
        
        try:
            with open(self.device_path, 'rb') as fd:
                # VIDIOC_QUERYCAP í˜¸ì¶œ
                cap_struct = bytearray(104)  # v4l2_capability êµ¬ì¡°ì²´ í¬ê¸°
                fcntl.ioctl(fd.fileno(), VIDIOC_QUERYCAP, cap_struct)
                
                # ê²°ê³¼ íŒŒì‹±
                driver = cap_struct[0:16].decode('utf-8', errors='ignore').rstrip('\x00')
                card = cap_struct[16:48].decode('utf-8', errors='ignore').rstrip('\x00')
                bus_info = cap_struct[48:80].decode('utf-8', errors='ignore').rstrip('\x00')
                capabilities = struct.unpack('I', cap_struct[84:88])[0]
                
                self.log(f"Driver: {driver}")
                self.log(f"Card: {card}")
                self.log(f"Bus: {bus_info}")
                self.log(f"Capabilities: 0x{capabilities:08x}")
                
                # ê¸°ëŠ¥ í™•ì¸
                has_capture = bool(capabilities & V4L2_CAP_VIDEO_CAPTURE)
                has_streaming = bool(capabilities & V4L2_CAP_STREAMING)
                
                self.log(f"Video Capture: {'Yes' if has_capture else 'No'}")
                self.log(f"Streaming: {'Yes' if has_streaming else 'No'}")
                
                if has_capture and has_streaming:
                    self.log("V4L2 capabilities check passed", "SUCCESS")
                    return True
                else:
                    self.log("Required V4L2 capabilities missing", "ERROR")
                    return False
                    
        except Exception as e:
            self.log(f"V4L2 capabilities test failed: {e}", "ERROR")
            return False
    
    def test_opencv_integration(self):
        """OpenCV í†µí•© í…ŒìŠ¤íŠ¸"""
        self.log("Testing OpenCV integration...")
        
        try:
            self.cap = cv2.VideoCapture(self.device_path)
            if not self.cap.isOpened():
                self.log("Failed to open device with OpenCV", "ERROR")
                return False
                
            # ê¸°ë³¸ ì†ì„± ì½ê¸°
            width = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)
            height = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
            fps = self.cap.get(cv2.CAP_PROP_FPS)
            
            self.log(f"OpenCV Properties - Resolution: {width}x{height}, FPS: {fps}")
            
            # í”„ë ˆì„ ìº¡ì²˜ í…ŒìŠ¤íŠ¸
            ret, frame = self.cap.read()
            if ret:
                self.log(f"Frame captured: {frame.shape}, dtype: {frame.dtype}", "SUCCESS")
                return True
            else:
                self.log("Failed to capture frame", "ERROR")
                return False
                
        except Exception as e:
            self.log(f"OpenCV integration test failed: {e}", "ERROR")
            return False
    
    def test_continuous_capture(self, duration=10, target_fps=30):
        """ì—°ì† ìº¡ì²˜ í…ŒìŠ¤íŠ¸"""
        self.log(f"Testing continuous capture for {duration}s at {target_fps} FPS...")
        
        if not self.cap:
            self.log("OpenCV not initialized", "ERROR")
            return False
            
        frame_count = 0
        start_time = time.time()
        last_fps_time = start_time
        fps_frames = 0
        
        frame_times = []
        frame_sizes = []
        
        while time.time() - start_time < duration:
            ret, frame = self.cap.read()
            if ret:
                frame_count += 1
                fps_frames += 1
                current_time = time.time()
                frame_times.append(current_time)
                frame_sizes.append(frame.nbytes)
                
                # FPS ê³„ì‚° (ë§¤ì´ˆ)
                if current_time - last_fps_time >= 1.0:
                    current_fps = fps_frames / (current_time - last_fps_time)
                    self.log(f"Current FPS: {current_fps:.1f}, Total frames: {frame_count}")
                    last_fps_time = current_time
                    fps_frames = 0
                    
            else:
                self.log("Frame capture failed", "WARNING")
                time.sleep(0.001)  # ì‘ì€ ì§€ì—°
        
        total_time = time.time() - start_time
        avg_fps = frame_count / total_time
        
        # í†µê³„ ê³„ì‚°
        if len(frame_times) > 1:
            intervals = [frame_times[i] - frame_times[i-1] for i in range(1, len(frame_times))]
            avg_interval = np.mean(intervals)
            std_interval = np.std(intervals)
            jitter = std_interval / avg_interval * 100 if avg_interval > 0 else 0
            
            self.log(f"Capture Statistics:")
            self.log(f"  Total frames: {frame_count}")
            self.log(f"  Average FPS: {avg_fps:.2f}")
            self.log(f"  Frame interval: {avg_interval*1000:.2f}Â±{std_interval*1000:.2f}ms")
            self.log(f"  Timing jitter: {jitter:.1f}%")
            self.log(f"  Average frame size: {np.mean(frame_sizes)/1024:.1f} KB")
            
            # ì„±ëŠ¥ í‰ê°€
            if avg_fps >= target_fps * 0.9:  # 90% ì´ìƒì´ë©´ ì„±ê³µ
                self.log("Continuous capture test passed", "SUCCESS")
                return True
            else:
                self.log(f"FPS too low: {avg_fps:.1f} < {target_fps * 0.9:.1f}", "WARNING")
                return False
        else:
            self.log("No frames captured", "ERROR")
            return False
    
    def test_format_changes(self):
        """í¬ë§· ë³€ê²½ í…ŒìŠ¤íŠ¸"""
        self.log("Testing format changes...")
        
        if not self.cap:
            self.log("OpenCV not initialized", "ERROR")
            return False
        
        test_formats = [
            (640, 480),
            (1280, 720),
            (1920, 1080),
            (320, 240),
        ]
        
        success_count = 0
        
        for width, height in test_formats:
            self.log(f"Testing format {width}x{height}...")
            
            # í¬ë§· ì„¤ì • ì‹œë„
            self.cap.set(cv2.CAP_PROP_FRAME_WIDTH, width)
            self.cap.set(cv2.CAP_PROP_FRAME_HEIGHT, height)
            
            # ì‹¤ì œ ì„¤ì •ëœ ê°’ í™•ì¸
            actual_width = self.cap.get(cv2.CAP_PROP_FRAME_WIDTH)
            actual_height = self.cap.get(cv2.CAP_PROP_FRAME_HEIGHT)
            
            # í”„ë ˆì„ ìº¡ì²˜í•´ì„œ ì‹¤ì œ í¬ê¸° í™•ì¸
            ret, frame = self.cap.read()
            if ret:
                frame_height, frame_width = frame.shape[:2]
                self.log(f"  Requested: {width}x{height}")
                self.log(f"  Property: {actual_width}x{actual_height}")
                self.log(f"  Actual frame: {frame_width}x{frame_height}")
                
                # ìœ ì—°í•œ ì„±ê³µ ê¸°ì¤€ (QEMUì—ì„œëŠ” ê³ ì • í•´ìƒë„ì¼ ìˆ˜ ìˆìŒ)
                if frame_width > 0 and frame_height > 0:
                    success_count += 1
                    self.log(f"  Format test passed", "SUCCESS")
                else:
                    self.log(f"  Invalid frame size", "ERROR")
            else:
                self.log(f"  Failed to capture frame", "ERROR")
        
        success_rate = success_count / len(test_formats)
        self.log(f"Format change test: {success_count}/{len(test_formats)} passed ({success_rate*100:.1f}%)")
        
        return success_rate >= 0.5  # 50% ì´ìƒ ì„±ê³µí•˜ë©´ í†µê³¼
    
    def test_frame_analysis(self):
        """í”„ë ˆì„ ë‚´ìš© ë¶„ì„ í…ŒìŠ¤íŠ¸"""
        self.log("Testing frame content analysis...")
        
        if not self.cap:
            self.log("OpenCV not initialized", "ERROR")
            return False
        
        frames = []
        for i in range(10):
            ret, frame = self.cap.read()
            if ret:
                frames.append(frame)
            time.sleep(0.1)
        
        if not frames:
            self.log("No frames captured for analysis", "ERROR")
            return False
        
        # í”„ë ˆì„ ë¶„ì„
        first_frame = frames[0]
        last_frame = frames[-1]
        
        # í†µê³„ ê³„ì‚°
        mean_first = np.mean(first_frame, axis=(0, 1))
        mean_last = np.mean(last_frame, axis=(0, 1))
        
        # í”„ë ˆì„ ê°„ ì°¨ì´
        frame_diff = np.mean(np.abs(first_frame.astype(float) - last_frame.astype(float)))
        
        # ìƒ‰ìƒ ë¶„í¬
        hist_b = cv2.calcHist([first_frame], [0], None, [256], [0, 256])
        hist_g = cv2.calcHist([first_frame], [1], None, [256], [0, 256])
        hist_r = cv2.calcHist([first_frame], [2], None, [256], [0, 256])
        
        # ì—”íŠ¸ë¡œí”¼ ê³„ì‚° (ë³µì¡ë„ ì¸¡ì •)
        def calculate_entropy(hist):
            hist_norm = hist.flatten() / np.sum(hist)
            hist_norm = hist_norm[hist_norm > 0]  # 0 ì œê±°
            return -np.sum(hist_norm * np.log2(hist_norm))
        
        entropy_b = calculate_entropy(hist_b)
        entropy_g = calculate_entropy(hist_g)
        entropy_r = calculate_entropy(hist_r)
        
        self.log(f"Frame Analysis Results:")
        self.log(f"  First frame mean BGR: ({mean_first[0]:.1f}, {mean_first[1]:.1f}, {mean_first[2]:.1f})")
        self.log(f"  Last frame mean BGR: ({mean_last[0]:.1f}, {mean_last[1]:.1f}, {mean_last[2]:.1f})")
        self.log(f"  Frame difference: {frame_diff:.2f}")
        self.log(f"  Color entropy BGR: ({entropy_b:.2f}, {entropy_g:.2f}, {entropy_r:.2f})")
        
        # í”„ë ˆì„ì´ ë³€í™”í•˜ê³  ìˆëŠ”ì§€ í™•ì¸ (QEMU ë“œë¼ì´ë²„ê°€ ì• ë‹ˆë©”ì´ì…˜ì„ ìƒì„±í•˜ëŠ”ì§€)
        has_variation = frame_diff > 1.0 or max(entropy_b, entropy_g, entropy_r) > 3.0
        
        if has_variation:
            self.log("Frame content shows variation", "SUCCESS")
        else:
            self.log("Frame content appears static", "WARNING")
        
        return True
    
    def test_threaded_capture(self, duration=5):
        """ë©€í‹°ìŠ¤ë ˆë“œ ìº¡ì²˜ í…ŒìŠ¤íŠ¸"""
        self.log(f"Testing threaded capture for {duration}s...")
        
        def capture_worker():
            """ìº¡ì²˜ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
            frame_count = 0
            while not self.stop_capture:
                ret, frame = self.cap.read()
                if ret:
                    try:
                        self.frame_queue.put(frame, timeout=0.1)
                        frame_count += 1
                    except queue.Full:
                        pass  # íê°€ ê°€ë“ ì°¬ ê²½ìš° ë¬´ì‹œ
                else:
                    time.sleep(0.001)
            self.log(f"Capture worker finished, captured {frame_count} frames")
        
        def process_worker():
            """ì²˜ë¦¬ ì›Œì»¤ ìŠ¤ë ˆë“œ"""
            processed_count = 0
            while not self.stop_capture or not self.frame_queue.empty():
                try:
                    frame = self.frame_queue.get(timeout=1.0)
                    # ê°„ë‹¨í•œ ì²˜ë¦¬ (í‰ê·  ê³„ì‚°)
                    mean_value = np.mean(frame)
                    processed_count += 1
                    if processed_count % 30 == 0:
                        self.log(f"Processed {processed_count} frames, last mean: {mean_value:.1f}")
                except queue.Empty:
                    break
            self.log(f"Process worker finished, processed {processed_count} frames")
            return processed_count
        
        if not self.cap:
            self.log("OpenCV not initialized", "ERROR")
            return False
        
        # ìŠ¤ë ˆë“œ ì‹œì‘
        self.stop_capture = False
        capture_thread = threading.Thread(target=capture_worker)
        process_thread = threading.Thread(target=process_worker)
        
        start_time = time.time()
        capture_thread.start()
        process_thread.start()
        
        # ì§€ì •ëœ ì‹œê°„ ëŒ€ê¸°
        time.sleep(duration)
        
        # ìº¡ì²˜ ì¤‘ì§€
        self.stop_capture = True
        capture_thread.join(timeout=2.0)
        process_thread.join(timeout=2.0)
        
        total_time = time.time() - start_time
        queue_size = self.frame_queue.qsize()
        
        self.log(f"Threaded capture completed:")
        self.log(f"  Duration: {total_time:.2f}s")
        self.log(f"  Remaining queue size: {queue_size}")
        
        # í ì •ë¦¬
        while not self.frame_queue.empty():
            try:
                self.frame_queue.get_nowait()
            except queue.Empty:
                break
        
        self.log("Threaded capture test passed", "SUCCESS")
        return True
    
    def save_test_results(self, filename="csi2_v4l2_test_results.json"):
        """í…ŒìŠ¤íŠ¸ ê²°ê³¼ ì €ì¥"""
        self.log(f"Saving test results to {filename}...")
        
        results = {
            "timestamp": time.strftime("%Y-%m-%d %H:%M:%S"),
            "device_path": self.device_path,
            "opencv_version": cv2.__version__,
            "tests": self.test_results
        }
        
        with open(filename, 'w') as f:
            json.dump(results, f, indent=2)
        
        self.log(f"Test results saved", "SUCCESS")
    
    def cleanup(self):
        """ì •ë¦¬"""
        if self.cap:
            self.cap.release()
            self.cap = None
        self.log("Cleanup completed")
    
    def run_all_tests(self):
        """ëª¨ë“  í…ŒìŠ¤íŠ¸ ì‹¤í–‰"""
        self.log("ğŸš€ Starting Advanced CSI2-V4L2 Integration Test")
        self.log("=" * 60)
        
        tests = [
            ("Device Discovery", self.test_device_discovery),
            ("V4L2 Capabilities", self.test_v4l2_capabilities),
            ("OpenCV Integration", self.test_opencv_integration),
            ("Continuous Capture", lambda: self.test_continuous_capture(duration=5)),
            ("Format Changes", self.test_format_changes),
            ("Frame Analysis", self.test_frame_analysis),
            ("Threaded Capture", lambda: self.test_threaded_capture(duration=3)),
        ]
        
        passed = 0
        total = len(tests)
        
        for test_name, test_func in tests:
            self.log(f"\nğŸ§ª Running test: {test_name}")
            self.log("-" * 40)
            
            try:
                result = test_func()
                self.test_results[test_name] = {
                    "passed": result,
                    "timestamp": time.strftime("%H:%M:%S")
                }
                
                if result:
                    passed += 1
                    self.log(f"âœ… Test '{test_name}' PASSED")
                else:
                    self.log(f"âŒ Test '{test_name}' FAILED")
                    
            except Exception as e:
                self.log(f"ğŸ’¥ Test '{test_name}' CRASHED: {e}", "ERROR")
                self.test_results[test_name] = {
                    "passed": False,
                    "error": str(e),
                    "timestamp": time.strftime("%H:%M:%S")
                }
        
        # ê²°ê³¼ ìš”ì•½
        self.log("\n" + "=" * 60)
        self.log("ğŸ¯ TEST SUMMARY")
        self.log("=" * 60)
        
        for test_name, result in self.test_results.items():
            status = "âœ… PASS" if result["passed"] else "âŒ FAIL"
            self.log(f"{status} {test_name}")
            if "error" in result:
                self.log(f"     Error: {result['error']}")
        
        success_rate = passed / total * 100
        self.log(f"\nğŸ“Š Overall Success Rate: {passed}/{total} ({success_rate:.1f}%)")
        
        if success_rate >= 80:
            self.log("ğŸ‰ CSI2-V4L2 Integration: EXCELLENT!", "SUCCESS")
        elif success_rate >= 60:
            self.log("ğŸ‘ CSI2-V4L2 Integration: GOOD", "SUCCESS")
        elif success_rate >= 40:
            self.log("âš ï¸  CSI2-V4L2 Integration: ACCEPTABLE", "WARNING")
        else:
            self.log("âŒ CSI2-V4L2 Integration: NEEDS WORK", "ERROR")
        
        # ê²°ê³¼ ì €ì¥
        self.save_test_results()
        
        return success_rate >= 60

def main():
    """ë©”ì¸ í•¨ìˆ˜"""
    device_path = "/dev/video0"
    
    # ëª…ë ¹ì¤„ ì¸ìˆ˜ ì²˜ë¦¬
    if len(sys.argv) > 1:
        device_path = sys.argv[1]
    
    tester = CSI2V4L2Tester(device_path)
    
    try:
        success = tester.run_all_tests()
        sys.exit(0 if success else 1)
    finally:
        tester.cleanup()

if __name__ == "__main__":
    main()
